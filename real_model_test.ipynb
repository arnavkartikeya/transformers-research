{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "407cad0b-132b-4626-aeb1-e1643985c248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 20:12:54.692051: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-14 20:12:55.656252: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import keras_nlp\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.layers import TextVectorization\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "from pprint import pprint\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "import re \n",
    "import sys \n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2752019-ab13-43e8-b473-22f09537971d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from '/home/jovyan/config.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import model \n",
    "import config\n",
    "import dataset\n",
    "from config import get_config, set_config_ratio\n",
    "from dataset import get_dataset_class\n",
    "from model import compile_model, get_optimizer\n",
    "importlib.reload(model)\n",
    "importlib.reload(dataset) \n",
    "importlib.reload(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c34ed-5cc3-4a02-b01f-ce3b86daa721",
   "metadata": {},
   "source": [
    "## Setup WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50cee4f2-6dad-43c7-b3e1-5df29f49a699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "546639ae-bda0-48f6-ac67-b1c1cc97834c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marnavkartikeya\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2afadb34-1b0e-4069-90a6-0f1bfd2502ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config() \n",
    "dataset = get_dataset_class(config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4fe8109-7316-4e4a-80c9-f8d51ffde136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 20:12:59.690193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22400 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:89:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting generating masks...\n",
      "starting generating mask for 0/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 1000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 2000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 3000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 4000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 5000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 6000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 7000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 8000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 9000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 10000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 11000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 12000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 13000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 14000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 15000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 16000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 17000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 18000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 19000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 20000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 21000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 22000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 23000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 24000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 25000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 26000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 27000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 28000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 29000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 30000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 31000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 32000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 33000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 34000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 35000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 36000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 37000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 38000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 39000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 40000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 41000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 42000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 43000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 44000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 45000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 46000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 47000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 48000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 49000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "exited loop\n",
      "converted mask to numpy array\n",
      "finished generating mask\n",
      "started forming dataset\n",
      "finished forming dataset\n"
     ]
    }
   ],
   "source": [
    "mlm_ds = dataset.generate_dataset().shuffle(1000).batch(config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03435be-d5f9-4878-ac26-aa4655f72d75",
   "metadata": {},
   "source": [
    "### Cell below test serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5765628c-3963-46ee-92cb-75fe54a5e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = compile_model(config)\n",
    "out = next(iter(mlm_ds.take(1)))\n",
    "# x, y, mask, padding_mask, sample_weights = out\n",
    "# before_save_pred = my_model((x, mask, padding_mask))\n",
    "# my_model.save('./my_tf_model')\n",
    "# saved_model = keras.models.load_model('./my_tf_model', compile=False) \n",
    "# # saved_model.summary()\n",
    "# saved_model.compile(optimizer='sgd', metrics=[\"accuracy\"]) #add parameter run_eagerly=True if this shit doesnt work \n",
    "# saved_model((x, mask, padding_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "784665f8-93ee-4806-94a7-54c3914966e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataset, text, k, output_attention):\n",
    "    #k = get the top k answers as an array\n",
    "    encoded_text = dataset.encode(text) \n",
    "    mask_index = np.where(encoded_text == 29999)[0][0] \n",
    "    mask, padding_mask = dataset.generate_mask(encoded_text)\n",
    "    # print(f'mask shape: {mask.shape}') \n",
    "    # print(f'padding mask: {padding_mask.shape}')\n",
    "    encoded_text = np.expand_dims(encoded_text, axis=0)\n",
    "    mask = np.expand_dims(mask, axis=0)\n",
    "    padding_mask = np.expand_dims(padding_mask, axis=0)\n",
    "\n",
    "    # print(mask_index)\n",
    "\n",
    "    encoded_text_tensor = tf.convert_to_tensor(encoded_text, dtype=tf.int32)\n",
    "    mask_tensor = tf.convert_to_tensor(mask, dtype=tf.bool)\n",
    "    padding_mask_tensor = tf.convert_to_tensor(padding_mask, dtype=tf.bool)\n",
    "    \n",
    "\n",
    "    data = (encoded_text_tensor, mask_tensor, padding_mask_tensor, sample_weights) \n",
    "    if output_attention: \n",
    "        prediction, attention = model(data)\n",
    "        prediction = dataset.decode(np.argsort(prediction[0][mask_index])[::-1][:k])\n",
    "        prediction = prediction.split() \n",
    "        return prediction, attention\n",
    "    prediction, _ = model(data)\n",
    "    prediction = dataset.decode(np.argsort(prediction[0][mask_index])[::-1][:k])\n",
    "    prediction = prediction.split() \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d72f3f92-dee6-45c7-93ff-8ee51a508579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_acc(logits, x_input, y_input, verbose=0):\n",
    "    '''\n",
    "    logits: Tensor, shape: (batch, 256, 30000)\n",
    "    x_input: Tensor, shape: (batch, 256) \n",
    "    y_input: Tensor, shape: (batch, 256) \n",
    "    ''' \n",
    "    logs = logits.numpy()\n",
    "    logs = np.argmax(logs, axis=-1).flatten() #shape: (batchx256) \n",
    "\n",
    "    # x = x_input.numpy().flatten() \n",
    "    y = y_input.numpy().flatten() \n",
    "    \n",
    "    pred_diff = np.count_nonzero(np.abs(logs-y)) \n",
    "\n",
    "    return (pred_diff)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a793df96-1e4f-4615-9a0a-8da4c0c13176",
   "metadata": {},
   "outputs": [],
   "source": [
    "attentions = [] \n",
    "config.NUM_LAYERS=2\n",
    "def train(epochs=2, config=config, mlm_ds=mlm_ds, step_size_ratio=1, dataset=dataset, log_to_wandb=False):\n",
    "    global attentions\n",
    "    ratio_ranges = np.arange(0, 1+step_size_ratio, step_size_ratio) \n",
    "\n",
    "    text = \"there was this great [mask] at the theatre today, it was quite long but also really fun to watch with friends\"\n",
    "    k = 5\n",
    "    output_attention = True \n",
    "\n",
    "    model_to_return = None\n",
    "    \n",
    "    for ratio in ratio_ranges:\n",
    "        if ratio >= 1: \n",
    "            break \n",
    "        config.RATIO = ratio\n",
    "        print(f\"Training model for ratio = {config.RATIO}\") \n",
    "        print(\"building model with custom config\") \n",
    "        model = compile_model(config)\n",
    "        print(\"finished building model\") \n",
    "        optimizer = get_optimizer() \n",
    "        loss_fn = keras.losses.SparseCategoricalCrossentropy(reduction=\"none\")\n",
    "        loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "        epoch_count = 0\n",
    "        print(\"started training\")\n",
    "        run = None \n",
    "        if(log_to_wandb): \n",
    "            run = wandb.init(\n",
    "                # Set the project where this run will be logged\n",
    "                project=\"encoder-mlm-real\",\n",
    "                # Track hyperparameters and run metadata\n",
    "                config={\n",
    "                    \"ratio\": ratio,\n",
    "                    \"epochs\": epochs,\n",
    "                    \"lr\": config.LR\n",
    "                },\n",
    "            )\n",
    "            run.name=f\"Ratio: {ratio}, Epochs: {epochs}\" \n",
    "        for epoch in range(epochs): \n",
    "            for step, (x_input, y_input, mask, padding_mask, sample_weights) in enumerate(mlm_ds): \n",
    "                start_time = time.time()\n",
    "                with tf.GradientTape() as tape: \n",
    "                    # print(f\"mask shape: {mask.shape}\")\n",
    "                    logits, _ = model((x_input, mask, padding_mask)) #do not output attention \n",
    "                    loss_value = loss_fn(y_input, logits, sample_weight=sample_weights)\n",
    "                    \n",
    "                grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "                \n",
    "                optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "                loss_tracker.update_state(loss_value, sample_weight=sample_weights)\n",
    "\n",
    "                # acc = measure_acc(logits, x_input, y_input, verbose=1) \n",
    "                if(log_to_wandb):\n",
    "                    wandb.log({\"loss\": loss_tracker.result(), \"acc\": acc})\n",
    "\n",
    "                if step%100 != 0:\n",
    "                    print(f\"\\rEpoch: {epoch}, Step {step + 1}, Loss: {loss_tracker.result().numpy():.4f}, Time: {time.time()-start_time:.3f} sec\", end='', flush=True)\n",
    "                \n",
    "                if step % 100 == 0:\n",
    "                    print(\"GETTING ACCURACY\") \n",
    "                    print(\"------------------------\") \n",
    "                    avg = 0 \n",
    "                    preds = logits.numpy().argmax(axis=-1) \n",
    "                    for i in range(16):\n",
    "                        indices = np.where(x_input.numpy()[i] == 29999)[0]\n",
    "                        if i == 15:                            \n",
    "                            print(\"predictions\")\n",
    "                            print(dataset.decode(y_input.numpy()[i][indices]))\n",
    "                            print(\"outputs\") \n",
    "                            print(dataset.decode(preds[i][indices]))\n",
    "                        print(f\"accuracy: {1-(np.count_nonzero(y_input.numpy()[i][indices] - preds[i][indices]))/y_input.numpy()[i][indices].shape[0]}\")\n",
    "                        print(\"------------------------\") \n",
    "                    # results = model.evaluate(mlm_ds\n",
    "                    # print(\"Training loss (for one batch) at step %d: %.4f\"% (step, float(loss_value))\n",
    "                    # )\n",
    "                    # print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n",
    "            epoch_count += 1\n",
    "            #save the model \n",
    "        model.save(f\"saved_models/model_ratio_{config.RATIO}\")\n",
    "        if(log_to_wandb):\n",
    "            wandb.finish()\n",
    "        \n",
    "        # # return model #adding this for now \n",
    "        # print(\"--------------EXAMPLE PREDICTION----------------\")\n",
    "        # prediction, attention = predict(model, dataset, text, k, output_attention)\n",
    "        # attentions.append(attention)\n",
    "        # print(prediction)\n",
    "        # print(\"--------------END OF PREDICTION----------------\")\n",
    "        # model_to_return = model \n",
    "    return None \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d301cab-65e7-42b2-97c5-837f5c399636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for ratio = 0.0\n",
      "building model with custom config\n",
      "finished building model\n",
      "started training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 20:24:33.681854: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-05-14 20:24:33.746381: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2024-05-14 20:24:34.109209: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5624cc4b1810 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-14 20:24:34.109249: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-05-14 20:24:34.116192: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-14 20:24:34.342472: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f66a0689120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f66a0689120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "GETTING ACCURACY\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "predictions\n",
      "goer my short years surprised this did sometime i this it\n",
      "outputs\n",
      "thoughtless steiner drugs aided fisherman botch infiltrating wheaton aided infiltrating defends\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "Epoch: 0, Step 100, Loss: 10.2593, Time: 0.451 secGETTING ACCURACY\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.05882352941176472\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "accuracy: 0.0\n",
      "------------------------\n",
      "predictions\n",
      "been lot caper only yum i was if is to look oh cares typical teen played\n",
      "outputs\n",
      "is is think inexplicable think think think surprise is more be think than be be be\n",
      "accuracy: 0.0625\n",
      "------------------------\n",
      "Epoch: 0, Step 165, Loss: 10.2202, Time: 0.193 sec"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 44\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epochs, config, mlm_ds, step_size_ratio, dataset, log_to_wandb)\u001b[0m\n\u001b[1;32m     41\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape: \n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# print(f\"mask shape: {mask.shape}\")\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     logits, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#do not output attention \u001b[39;00m\n\u001b[1;32m     45\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m loss_fn(y_input, logits, sample_weight\u001b[38;5;241m=\u001b[39msample_weights)\n\u001b[1;32m     47\u001b[0m grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss_value, model\u001b[38;5;241m.\u001b[39mtrainable_weights)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py:569\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    567\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/engine/base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1149\u001b[0m ):\n\u001b[0;32m-> 1150\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/model.py:271\u001b[0m, in \u001b[0;36mTransformerModel.call\u001b[0;34m(self, inputs, output_attention)\u001b[0m\n\u001b[1;32m    269\u001b[0m attention \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_layers):\n\u001b[0;32m--> 271\u001b[0m     x, attention \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     attentions\u001b[38;5;241m.\u001b[39mappend(attention)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attention:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/engine/base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1149\u001b[0m ):\n\u001b[0;32m-> 1150\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/model.py:118\u001b[0m, in \u001b[0;36mEncoderLayer.call\u001b[0;34m(self, x, syntactic_masks, padding_masks, training)\u001b[0m\n\u001b[1;32m    115\u001b[0m multihead_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(multihead_output)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Followed by an Add & Norm layer\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m addnorm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_norm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultihead_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Expected output shape = (batch_size, sequence_length, d_model)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Followed by a fully connected layer\u001b[39;00m\n\u001b[1;32m    122\u001b[0m feedforward_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward(addnorm_output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/engine/base_layer.py:1128\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1125\u001b[0m     name_scope \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_unnested_name_scope()\n\u001b[1;32m   1126\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autographed_call()\n\u001b[0;32m-> 1128\u001b[0m call_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtraceback_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minject_argument_info_in_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcall_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlayer \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m (type \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mExitStack() \u001b[38;5;28;01mas\u001b[39;00m namescope_stack:\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_name_scope_on_model_declaration_enabled:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:160\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback\u001b[0;34m(fn, object_name)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m signature\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m bound_signature\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecorator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_decorator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_handler\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/util/tf_decorator.py:136\u001b[0m, in \u001b[0;36mmake_decorator\u001b[0;34m(target, decorator_func, decorator_name, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decorator_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m   decorator_name \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mcurrentframe()\u001b[38;5;241m.\u001b[39mf_back\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_name\n\u001b[0;32m--> 136\u001b[0m decorator \u001b[38;5;241m=\u001b[39m \u001b[43mTFDecorator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecorator_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorator_doc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdecorator_argspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28msetattr\u001b[39m(decorator_func, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_tf_decorator\u001b[39m\u001b[38;5;124m'\u001b[39m, decorator)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Objects that are callables (e.g., a functools.partial object) may not have\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# the following attributes.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/util/tf_decorator.py:332\u001b[0m, in \u001b[0;36mTFDecorator.__init__\u001b[0;34m(self, decorator_name, target, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(target):\n\u001b[1;32m    331\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__signature__ \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;66;03m# Certain callables such as builtins can not be inspected for signature.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/inspect.py:3280\u001b[0m, in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msignature\u001b[39m(obj, \u001b[38;5;241m*\u001b[39m, follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   3279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3281\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/inspect.py:3028\u001b[0m, in \u001b[0;36mSignature.from_callable\u001b[0;34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_callable\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   3026\u001b[0m                   follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   3027\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3028\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigcls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3029\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mfollow_wrapper_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3030\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/inspect.py:2454\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m is not a callable object\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj))\n\u001b[1;32m   2451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, types\u001b[38;5;241m.\u001b[39mMethodType):\n\u001b[1;32m   2452\u001b[0m     \u001b[38;5;66;03m# In this case we skip the first parameter of the underlying\u001b[39;00m\n\u001b[1;32m   2453\u001b[0m     \u001b[38;5;66;03m# function (usually `self` or `cls`).\u001b[39;00m\n\u001b[0;32m-> 2454\u001b[0m     sig \u001b[38;5;241m=\u001b[39m \u001b[43m_get_signature_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__func__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2456\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m skip_bound_arg:\n\u001b[1;32m   2457\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _signature_bound_method(sig)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/inspect.py:2516\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2511\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m sig\u001b[38;5;241m.\u001b[39mreplace(parameters\u001b[38;5;241m=\u001b[39mnew_params)\n\u001b[1;32m   2513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isfunction(obj) \u001b[38;5;129;01mor\u001b[39;00m _signature_is_functionlike(obj):\n\u001b[1;32m   2514\u001b[0m     \u001b[38;5;66;03m# If it's a pure Python function, or an object that is duck type\u001b[39;00m\n\u001b[1;32m   2515\u001b[0m     \u001b[38;5;66;03m# of a Python function (Cython functions, for instance), then:\u001b[39;00m\n\u001b[0;32m-> 2516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2517\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mskip_bound_arg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_bound_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2518\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _signature_is_builtin(obj):\n\u001b[1;32m   2521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _signature_from_builtin(sigcls, obj,\n\u001b[1;32m   2522\u001b[0m                                    skip_bound_arg\u001b[38;5;241m=\u001b[39mskip_bound_arg)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/inspect.py:2360\u001b[0m, in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   2358\u001b[0m keyword_only_count \u001b[38;5;241m=\u001b[39m func_code\u001b[38;5;241m.\u001b[39mco_kwonlyargcount\n\u001b[1;32m   2359\u001b[0m keyword_only \u001b[38;5;241m=\u001b[39m arg_names[pos_count:pos_count \u001b[38;5;241m+\u001b[39m keyword_only_count]\n\u001b[0;32m-> 2360\u001b[0m annotations \u001b[38;5;241m=\u001b[39m \u001b[43mget_annotations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2361\u001b[0m defaults \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__defaults__\u001b[39m\n\u001b[1;32m   2362\u001b[0m kwdefaults \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__kwdefaults__\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/inspect.py:167\u001b[0m, in \u001b[0;36mget_annotations\u001b[0;34m(obj, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# See Include/object.h\u001b[39;00m\n\u001b[1;32m    164\u001b[0m TPFLAGS_IS_ABSTRACT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<<\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_annotations\u001b[39m(obj, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    168\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the annotations dict for an object.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m    obj may be a callable, class, or module.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m        functools.update_wrapper()) it is first unwrapped.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mtype\u001b[39m):\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;66;03m# class\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train(epochs=20, step_size_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03f706b3-55e6-4cbe-91c6-dd96de1f94fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_0 = keras.models.load_model('saved_models/model_ratio_0.0', compile=False)\n",
    "saved_model_8 = keras.models.load_model('saved_models/model_ratio_0.5', compile=False) \n",
    "optim = get_optimizer()\n",
    "saved_model_0.compile(optimizer=optim, metrics=['accuracy'])\n",
    "saved_model_8.compile(optimizer=optim, metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5437c989-8ee4-4f78-8c6b-3e91dd684e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"there was this great film at the theatre today, it was really long but also very fun to watch with friends\"\n",
    "text = \"there was this great film at the theatre today, it was really long but also [mask] fun to watch with friends\"\n",
    "#k = get the top k answers as an array\n",
    "encoded_text = dataset.encode(text) \n",
    "mask_index = np.where(encoded_text == 29999)[0][0] \n",
    "mask, padding_mask = dataset.generate_mask(encoded_text)\n",
    "# print(f'mask shape: {mask.shape}') \n",
    "# print(f'padding mask: {padding_mask.shape}')\n",
    "encoded_text = np.expand_dims(encoded_text, axis=0)\n",
    "mask = np.expand_dims(mask, axis=0)\n",
    "padding_mask = np.expand_dims(padding_mask, axis=0)\n",
    "\n",
    "encoded_text_tensor = tf.convert_to_tensor(encoded_text, dtype=tf.int32)\n",
    "mask_tensor = tf.convert_to_tensor(mask, dtype=tf.bool)\n",
    "padding_mask_tensor = tf.convert_to_tensor(padding_mask, dtype=tf.bool)\n",
    "\n",
    "\n",
    "data = (encoded_text_tensor, mask_tensor, padding_mask_tensor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcca7a79-381c-4565-8868-c8bc5cfc6ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 03:01:21.355890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-05-14 03:01:21.363842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n"
     ]
    }
   ],
   "source": [
    "out_0, attention_0 = saved_model_0(data) \n",
    "out_8, attention_8 = saved_model_8(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dfbe4a4-157f-4455-a03b-af1a8fd253af",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'saved_model_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m (x_data_tensor, syntactic_mask_tensor, padding_mask_tensor)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m \n\u001b[0;32m---> 10\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43msaved_model_0\u001b[49m(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m     11\u001b[0m preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(out[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m16\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'saved_model_0' is not defined"
     ]
    }
   ],
   "source": [
    "x = None \n",
    "y = None \n",
    "weights = None \n",
    "out = None \n",
    "for (x_data_tensor, y_data_tensor, syntactic_mask_tensor, padding_mask_tensor, sample_weights_tensor) in mlm_ds:\n",
    "    y = y_data_tensor \n",
    "    x = x_data_tensor\n",
    "    input = (x_data_tensor, syntactic_mask_tensor, padding_mask_tensor)\n",
    "    break \n",
    "out = saved_model_0(input)\n",
    "preds = np.argmax(out[0].numpy(), axis=-1)\n",
    "for i in range(16):\n",
    "    indices = np.where(x.numpy()[i] == 29999)[0]\n",
    "    print(\"predictions\")\n",
    "    print(dataset.decode(y.numpy()[i][indices]))\n",
    "    print(\"outputs\") \n",
    "    print(dataset.decode(preds[i][indices]))\n",
    "    print(f\"accuracy: {1-(np.count_nonzero(y.numpy()[i][indices] - preds[i][indices]))/y.numpy()[i][indices].shape[0]}\")\n",
    "    print(\"------------------------\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b746dbae-b6d5-48fc-a3e0-979436af0275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x data tensor: [ 2585 10289     7 10491  1024   184   533    36    15  9444    35     4\n",
      "     1  1476    45     4 29999     5  1028 29999     2   395    36 10097\n",
      "    41    82    11 29999     7    21   289    36  2112   229    42    41\n",
      "   627 29999  1717     8     2   755  3540    32  1913    36   309     8\n",
      " 21743     6   160   154    17 29999  5120    82 29999    36   192    11\n",
      " 29999    57  1295     6   245     9    13   860 29999     2  1037   172\n",
      "    97    60    25   265   479    39   283 29999     5   759    82     2\n",
      "   100     3     2   172   515   150   450     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "-------------------------\n",
      "y data tensor: [ 2585 10289     7     4  1024   184   533    36    15  9444    35     4\n",
      "     1  1476    45     4   164     5  1028   515     2   395    36 10097\n",
      "    41    82    11  4870     7    21   289    36  2112   229    42    41\n",
      "   627    10  1717     8     2   755  3540    32  1913    36   309     8\n",
      " 21743     6   160   154    17     6  5120    82  1493    36   192    11\n",
      "    17    57  1295     6   245     9    13   860   430     2  1037   172\n",
      "    97    60    25   265   479    39   283   224     5   759    82     2\n",
      "   100     3     2   172   515   150   450     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "-------------------------\n",
      "x data tensor: [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "-------------------------\n",
      "number of masked tokens: 9\n"
     ]
    }
   ],
   "source": [
    "x = None \n",
    "y = None \n",
    "for (x_data_tensor, y_data_tensor, syntactic_mask_tensor, padding_mask_tensor, sample_weights_tensor) in mlm_ds:\n",
    "    y = y_data_tensor \n",
    "    x = x_data_tensor\n",
    "    input = (x_data_tensor, syntactic_mask_tensor, padding_mask_tensor)\n",
    "    break \n",
    "print(f\"x data tensor: {x[0]}\") \n",
    "print(\"-------------------------\")\n",
    "print(f\"y data tensor: {y[0]}\") \n",
    "print(\"-------------------------\")\n",
    "print(f\"x data tensor: {sample_weights_tensor[0]}\") \n",
    "print(\"-------------------------\")\n",
    "print(f\"number of masked tokens: {np.where(x[0] == 29999)[0].shape[0]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cb1fcb3d-afef-4eb0-9d60-f226da1c25eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m attention_0[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m attention_0[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      3\u001b[0m attention_0[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m attention_0[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m----> 5\u001b[0m attention_8[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mattention_8\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m()\n\u001b[1;32m      6\u001b[0m attention_8[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m attention_8[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "from bertviz import model_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "53d012d3-d00e-4265-8b78-1e9663e8db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_attention_0 = attention_0 \n",
    "viz_attention_0[0] = attention_0[0][:, :, :21, :21].numpy()\n",
    "viz_attention_0[1] = attention_0[1][:, :, :21, :21].numpy()\n",
    "\n",
    "viz_attention_8 = attention_8  \n",
    "viz_attention_8[0] = attention_8[0][:, :, :21, :21].numpy()\n",
    "viz_attention_8[1] = attention_8[1][:, :, :21, :21].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6018e532-0779-4e18-b0d1-4a63f678a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "tf_0= viz_attention_0\n",
    "tf_8 = viz_attention_0\n",
    "tf_0[0] = torch.from_numpy(viz_attention_0[0]) \n",
    "tf_0[1] = torch.from_numpy(viz_attention_0[1]) \n",
    "tf_8[0] = torch.from_numpy(viz_attention_8[0]) \n",
    "tf_8[1] = torch.from_numpy(viz_attention_8[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c9a4567b-116e-4f8e-ae74-6648df8cd410",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_model_view_0 = model_view(tf_0, text.split(), html_action='return')\n",
    "with open(\"attention_viz/model_view_0.html\", 'w') as file:\n",
    "    file.write(html_model_view_0.data)\n",
    "\n",
    "html_model_view_8 = model_view(tf_8, text.split(), html_action='return')\n",
    "with open(\"attention_viz/model_view_8.html\", 'w') as file:\n",
    "    file.write(html_model_view_8.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a12934c4-582f-4383-9b14-25a55b58f69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'there was this great film at the as today it was [UNK] long but also a fun to watch with friends'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.decode(np.argmax(out[0][0].numpy(), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1955e80-d415-4b5b-a082-2327886776c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.encode(\"reigning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "787aa40d-cc04-4f68-8de2-084212617738",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dataset.id2token:\n",
    "    if dataset.id2token[key] == \"[mask]\": \n",
    "        print(key) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1ec5696-6a3e-4ae7-baed-71273a2067f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mask]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.decode([29999]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3760da04-ddd5-4d20-b5eb-3f6afe1072b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99458414 0.9898177  0.9917646  0.99501306 0.99558616 0.99439055\n",
      " 0.9988035  0.9817747  0.97407585 0.99605536 0.99747664 0.9984666\n",
      " 0.9944267  0.99824774 0.9892838  0.04622511 0.9959009  0.9979032\n",
      " 0.9920459  0.9979886  0.9969368  0.9999248  0.9999249  0.99992\n",
      " 0.9999112  0.9999014  0.9998957  0.99989533 0.9998995  0.9999124\n",
      " 0.99992716 0.99993575 0.9999378  0.9999378  0.99994123 0.9999453\n",
      " 0.99994934 0.9999529  0.99995625 0.9999573  0.99995816 0.9999583\n",
      " 0.99995756 0.99995637 0.99995625 0.9999554  0.9999536  0.9999505\n",
      " 0.99994874 0.9999511  0.99995506 0.99995637 0.9999552  0.99995244\n",
      " 0.99994886 0.99994385 0.9999398  0.99993885 0.99994147 0.9999466\n",
      " 0.9999503  0.99995375 0.99995565 0.99995613 0.99995494 0.9999552\n",
      " 0.99995637 0.9999572  0.99995625 0.9999541  0.99995077 0.9999472\n",
      " 0.99994504 0.9999455  0.9999509  0.9999516  0.9999492  0.99994934\n",
      " 0.99995255 0.999954   0.9999529  0.99995124 0.999946   0.9999386\n",
      " 0.9999366  0.9999374  0.99994206 0.9999478  0.99995184 0.9999523\n",
      " 0.99995184 0.9999509  0.9999498  0.9999503  0.9999522  0.9999547\n",
      " 0.99995804 0.9999608  0.9999614  0.99996126 0.99996006 0.9999596\n",
      " 0.9999596  0.9999596  0.99995923 0.9999591  0.99995935 0.9999591\n",
      " 0.9999577  0.9999566  0.99995625 0.99995613 0.99995506 0.99995434\n",
      " 0.99995255 0.9999535  0.99995613 0.9999584  0.99995947 0.9999591\n",
      " 0.9999585  0.9999573  0.9999566  0.99995685 0.9999585  0.99996006\n",
      " 0.99996245 0.99996436 0.9999658  0.99996614 0.9999665  0.99996686\n",
      " 0.9999659  0.9999646  0.999964   0.99996364 0.9999634  0.9999639\n",
      " 0.99996436 0.9999651  0.99996567 0.9999651  0.9999634  0.99996245\n",
      " 0.9999622  0.99996233 0.99996316 0.999964   0.999964   0.9999639\n",
      " 0.99996376 0.99996364 0.9999634  0.99996424 0.9999666  0.9999684\n",
      " 0.99996865 0.9999684  0.999967   0.9999664  0.99996674 0.9999676\n",
      " 0.9999676  0.9999677  0.99996793 0.9999676  0.9999685  0.99996924\n",
      " 0.9999701  0.99996984 0.9999684  0.99996686 0.9999653  0.9999658\n",
      " 0.9999671  0.9999682  0.99996805 0.99996793 0.9999678  0.9999683\n",
      " 0.9999685  0.99996746 0.9999658  0.99996364 0.99996364 0.9999646\n",
      " 0.9999651  0.99996495 0.9999646  0.9999641  0.99996376 0.9999641\n",
      " 0.9999645  0.99996555 0.9999664  0.99996674 0.9999676  0.9999685\n",
      " 0.99996877 0.9999682  0.99996686 0.99996555 0.999966   0.9999666\n",
      " 0.99996734 0.99996734 0.99996674 0.9999653  0.9999645  0.9999641\n",
      " 0.9999641  0.9999646  0.99996483 0.9999645  0.9999639  0.9999639\n",
      " 0.9999652  0.99996614 0.99996686 0.99996734 0.9999672  0.99996686\n",
      " 0.99996674 0.9999658  0.99996483 0.9999646  0.9999654  0.99996686\n",
      " 0.99996793 0.9999682  0.9999683  0.99996793 0.9999676  0.9999676\n",
      " 0.9999672  0.9999665  0.9999653  0.9999646  0.9999634  0.99996233\n",
      " 0.9999616  0.99996257 0.99996376 0.99996364 0.9999629  0.9999622\n",
      " 0.99996114 0.9999614  0.999961   0.99995947 0.9999579  0.9999572\n",
      " 0.9999577  0.9999583  0.99995923 0.9999596 ]\n",
      "[  47   13   11   80   19   30    2 1627  609    9   13    1  199   18\n",
      "   81   10  242    6  103   15  332    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "preds = prediction[0]\n",
    "print(np.max(preds, axis=-1))\n",
    "print(np.argmax(preds, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "019826e2-b22f-4565-9e20-f26a8f335a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a reigning'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.decode(dataset.encode(\"this is a [mask]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daab219a-ba08-4e52-bfa8-b76464e3645e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "correct: there\n",
      "prediction: there\n",
      "========================\n",
      "========================\n",
      "correct: was\n",
      "prediction: was\n",
      "========================\n",
      "========================\n",
      "correct: this\n",
      "prediction: this\n",
      "========================\n",
      "========================\n",
      "correct: great\n",
      "prediction: great\n",
      "========================\n",
      "========================\n",
      "correct: film\n",
      "prediction: film\n",
      "========================\n",
      "========================\n",
      "correct: at\n",
      "prediction: at\n",
      "========================\n",
      "========================\n",
      "correct: the\n",
      "prediction: the\n",
      "========================\n",
      "========================\n",
      "correct: theatre\n",
      "prediction: theatre\n",
      "========================\n",
      "========================\n",
      "correct: today,\n",
      "prediction: today\n",
      "========================\n",
      "========================\n",
      "correct: it\n",
      "prediction: it\n",
      "========================\n",
      "========================\n",
      "correct: was\n",
      "prediction: was\n",
      "========================\n",
      "========================\n",
      "correct: super\n",
      "prediction: film\n",
      "========================\n",
      "========================\n",
      "correct: long\n",
      "prediction: long\n",
      "========================\n",
      "========================\n",
      "correct: but\n",
      "prediction: but\n",
      "========================\n",
      "========================\n",
      "correct: also\n",
      "prediction: also\n",
      "========================\n",
      "========================\n",
      "correct: really\n",
      "prediction: it\n",
      "========================\n",
      "========================\n",
      "correct: fun\n",
      "prediction: fun\n",
      "========================\n",
      "========================\n",
      "correct: to\n",
      "prediction: to\n",
      "========================\n",
      "========================\n",
      "correct: watch\n",
      "prediction: watch\n",
      "========================\n",
      "========================\n",
      "correct: with\n",
      "prediction: with\n",
      "========================\n",
      "========================\n",
      "correct: friends\n",
      "prediction: friends\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "preds = prediction[0]\n",
    "preds = np.argmax(preds, axis=-1)\n",
    "real_text = y.split()\n",
    "for correct, pred in zip(real_text, preds): \n",
    "    if pred == 0:\n",
    "        break \n",
    "    else: \n",
    "        print(\"========================\")\n",
    "        print(f\"correct: {correct}\")\n",
    "        print(f\"prediction: {dataset.decode([pred])}\")\n",
    "        print(\"========================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6a8f8a-5669-43f2-bd56-d3b220213376",
   "metadata": {},
   "source": [
    "## Attention and Other Shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a5d7618e-fef5-4e56-bccf-789ac077833d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03773842 0.01787496 0.01448925 0.01764323 0.02313525 0.0369661\n",
      " 0.05562109 0.08916617 0.08994694 0.09715331 0.07790561 0.08223583\n",
      " 0.06563642 0.04593078 0.03129031 0.04033205 0.03472701 0.03084017\n",
      " 0.02977602 0.03660338 0.04498763]\n"
     ]
    }
   ],
   "source": [
    "print(attentions[0][0][0][:21, :21][0][0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56c55670-53ee-4d0a-a7f4-426db9455985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertviz import head_view, model_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24d67b84-1c8a-4541-ba69-cff7d9b89baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8, 21, 21)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming attentions[0][1].numpy() is 2D array of size larger than (9, 9)\n",
    "test = attentions[0][1].numpy()\n",
    "\n",
    "print(test[:,:,:21,:21].shape)  # Extract top left corner of size 9x9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "26cfc15e-c1ea-469c-9489-f028dc949a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "temp_attention = attentions \n",
    "temp_attention[0][0] = torch.tensor(attentions[0][0].numpy()[:,:,:21,:21])\n",
    "# temp_attention[0][1] = torch.tensor(attentions[0][1].numpy()[:,:,:21,:21])\n",
    "temp_attention[1][0] = torch.tensor(attentions[1][0].numpy()[:,:,:21,:21])\n",
    "# temp_attention[1][1] = torch.tensor(attentions[1][1].numpy()[:,:,:21,:21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fc0d926c-7514-4904-95d2-88d15bbaded5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "type(torch.tensor(attentions[0][0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0a98a32-6d8a-4fd0-8f9c-2f28bf40bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = \"there was this great [mask] at the theatre today, it was quite long but also really fun to watch with friends\".split()\n",
    "html_model_view = model_view(temp_attention[0], tokens, html_action=\"return\")\n",
    "with open(\"./model_view.html\", 'w') as file:\n",
    "    file.write(html_model_view.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ceb305f4-1a60-4d4a-8632-579702c135ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp_attention[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5428e03e-a5d8-45c0-9a8a-bf6430e0e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_model_view = model_view(temp_attention[1], tokens, html_action=\"return\")\n",
    "with open(\"./model_view_syntactic.html\", 'w') as file:\n",
    "    file.write(html_model_view.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2c3b083d-5e79-453f-9a6e-4079142111e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 256, 30000)\n"
     ]
    }
   ],
   "source": [
    "count = 0 \n",
    "for step, (x_input, y_input, syntactic_mask, padding_mask) in enumerate(mlm_ds): \n",
    "    logits = model((x_input, mask, padding_mask))\n",
    "    print(logits.shape)\n",
    "    if count == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9dcc09c7-fa21-41d4-8754-c0fb7baae2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    9  2658    11     7 29999   709    19  4279    15     2  4211    20\n",
      "   184   480    15    73   944     1     7     9     2   709    23    37\n",
      " 23288 29999    11   237     5   146 29999     2   631  1448     7    11\n",
      "    80     9    62   262   124    14 28497 29999     1     7   304    59\n",
      "  3576 29999   572  4294     6 29999 15859     5 23565 11081  6344     3\n",
      "  5283   284     8     4   724   822    18    59 29999 29999  1140 29999\n",
      "     2   294   386 29999    41  3750  8584     1  1884     7   237    76\n",
      "  5390    25   222     2   159     5  3967     2  1276  1837  6993  3575\n",
      "     8    11   411     5     2   145 12558     4  7307  1808     3    28\n",
      "     5     2 29999  4035 29999 16472     5    11   822 14750  1105 29999\n",
      "    65  2383     6   169 29999   702   206 29999    84 29999     2 29999\n",
      " 29999    12    31    80  2575    66   339    59   179    73 14148    12\n",
      " 19395     6  1639 29999 29999     2    65     5    41  1711  3108     7\n",
      "    37  2971    21    60 29999    59 13897 13914     3   867    82     4\n",
      " 10767   887   623    84     8   142   472 29999     6   122     1 11376\n",
      "     2 29999    95     6   782  1113   848    18 20687    13     4 29999\n",
      "  7049     3   863   522    24   328 19923   545     2    17   121     4\n",
      "   375 11946    32     1 29999   354  1399     3  1736   145 29999    65\n",
      "    52 29999 29999    21     8 29999 29999    99     1    55    84     8\n",
      "    46   923     1    95    29 15213     6    25    33 16142  2133  4431\n",
      " 29999   887 10972     3 29999     4   904   110  1469    15     4   132\n",
      "   168   189     6    26]\n",
      "(array([  4,  25,  30,  43,  49,  53,  68,  69,  71,  75, 110, 112, 119,\n",
      "       124, 127, 129, 131, 132, 147, 148, 160, 175, 181, 191, 208, 214,\n",
      "       217, 218, 221, 222, 240, 244]),)\n"
     ]
    }
   ],
   "source": [
    "print(x_input[1].numpy())\n",
    "print(np.where(x_input[1].numpy() == 29999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "64b5eb52-865a-4cbb-9ce3-2f431ce74688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reigning'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.decode(np.array([x_input[].numpy()[4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "61c3d3eb-02df-4403-8bcd-d576e6060ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anyone who has a remote reigning in science fiction should start at the basics everyone says star wars and star trek are the best mayan fiction films reigning begin at which is fine but the truth is the terminator and this movie reigning green are far better choices reigning those reigning reigning is probably science reigning s reigning kept secret it remains one of the biggest yet most forgotten reigning but the impact of its setting is tilted reigning a reality with each passing day charlton reigning [UNK] his role yet it works edward g robinson in his final role makes the most out of it in soylent reigning more than anyone else and reigning final reigning are touching it is manhattan in 2022 the world is [UNK] and reigning is an unbelievable fortune a cosmic reigning of strawberry jam costs 150 a big executive for the reigning company is murdered reigning police detective thorn is on the case the secret of soylent green reigning not a reigning if you do research reigning the movie soylent is enjoyable to watch but the whole screenplay is a reigning it is just as cheap as the entire production the screenplay and the over dramatics of the reigning made the movie yet were completely reigning reigning reigning to be a reigning and no one knows the rules specifically cop thorn who likes to just waltz into people s apartments [UNK] around shamelessly reigning steal anything he reigning the character s interactions keeps your attention reigning the movie but still\n"
     ]
    }
   ],
   "source": [
    "print(dataset.decode(x_input[0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "82da7735-5eb1-4dc2-9cc8-9021f9f7fea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anyone who has a remote interest in science fiction should start at the basics everyone says star wars and star trek are the best science fiction films to begin at which is fine but the truth is the terminator and this movie soylent green are far better choices than those series soylent is probably science fiction s best kept secret it remains one of the biggest yet most forgotten films but the impact of its setting is becoming more a reality with each passing day charlton heston [UNK] his role yet it works edward g robinson in his final role makes the most out of it in soylent green more than anyone else and his final scenes are touching it is manhattan in 2022 the world is [UNK] and food is an unbelievable fortune a small jar of strawberry jam costs 150 a big executive for the soylent company is murdered and police detective thorn is on the case the secret of soylent green is not a mystery if you do research on the movie soylent is enjoyable to watch but the whole screenplay is a joke it is just as cheap as the entire production the screenplay and the over dramatics of the actors made the movie yet were completely hilarious everyone seems to be a moron and no one knows the rules specifically cop thorn who likes to just waltz into people s apartments [UNK] around shamelessly and steal anything he wants the character s interactions keeps your attention on the movie but still\n"
     ]
    }
   ],
   "source": [
    "print(dataset.decode(y_input[0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "619a4f6b-b2ad-4d57-943c-8375d9fc55f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anyone who has a remote movie in science fiction should start at the basics everyone says star wars and star trek are the best mayan fiction films it begin at which is fine but the truth is the terminator and this movie it green are far better choices and those and it is probably science it s it kept secret it remains one of the biggest yet most forgotten that but the impact of its setting is is to a reality with each passing day charlton and [UNK] his role yet it works edward g robinson in his final role makes the most out of it in soylent and more than anyone else and and final and are touching it is manhattan in 2022'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.decode(np.argmax(logits[0], axis=-1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb69ba3-f5e4-4506-97d5-3ec54d95fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.where(x_input.numpy() == 29999)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7d7bd236-4380-48bf-8185-fcb48dcee225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2335f6dc-71d2-4618-8b80-3d314cf84bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a viewed the cover vision a interesting than you your is you i sympathy character fact downright unlikable as a forced trust little which hallucination source cover images film never event oh'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.decode(y_input[2].numpy()[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1ac02259-08cc-4773-8129-30d671a87c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a viewed the cover and a interesting than you it is you i and to to downright unlikable as a forced trust little which hallucination source cover images film never event oh'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.decode(np.argmax(logits[2].numpy()[indices], axis=-1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1bf18e62-6172-4e54-96fc-e4ce9d8b42d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17,  9,  9,  3,  3,  9,  9,  9, 12,  6,  3,  3,  3,  3,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(logits[0].numpy()[indices], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1f97dccf-3362-4773-b045-5b5e829ca00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_acc(logits, x_input, y_input, verbose=0):\n",
    "    '''\n",
    "    logits: Tensor, shape: (batch, 256, 30000)\n",
    "    x_input: Tensor, shape: (batch, 256) \n",
    "    y_input: Tensor, shape: (batch, 256) \n",
    "\n",
    "    ''' \n",
    "\n",
    "    total_correct = 0 \n",
    "    total = 0 \n",
    "\n",
    "    print(f\"x_input shape: {x_input.shape}\")\n",
    "    \n",
    "    for i in range(x_input.shape[0]): \n",
    "        x = x_input[i].numpy() #shape(1, 256) \n",
    "        y = y_input[i].numpy() #shape (1, 256) \n",
    "        indices = np.where(x_input[i] == 29999)\n",
    "        logs = logits[i].numpy() \n",
    "\n",
    "        logs = logs[indices] \n",
    "        logs = np.argsort(logs)[::-1] #(18, 30000)\n",
    "        logs = logs[:,:5] # (18, 5) \n",
    "\n",
    "        correct = y[indices] #(18,) \n",
    "\n",
    "        print(f\"logs shape: {logs.shape}\")\n",
    "        print(f\"correct shape: {correct.shape}\")\n",
    "\n",
    "        for j in range(logs.shape[0]): \n",
    "            if correct[j] in logs[j]: \n",
    "                total_correct += 1 \n",
    "            total += 1 \n",
    "\n",
    "        if verbose == 1: \n",
    "            print(correct)\n",
    "            print(f\"correct: {dataset.decode(correct)}\")\n",
    "            pred = [] \n",
    "            for i in logs: \n",
    "                pred.append(dataset.decode(i)) \n",
    "            print(f\"preds: {pred}\")\n",
    "        return total_correct/total \n",
    "    \n",
    "    # print(f\"x_input shape: {x_input.shape}\")\n",
    "    # indices = np.where(x_input == 29999) #type: tuple, shape: (32, num_masks) \n",
    "\n",
    "    # print(f\"indices shape: {len(indices)}\")\n",
    "    # print(f\"indices real shape: {indices[0].shape}\")\n",
    "    \n",
    "    # logs = logits.numpy() \n",
    "    # logits_top_k = np.argsort(logs, axis=-1)[::-1] #shape (32, 256, 30000)\n",
    "    # logits_top_k = logits_top_k[:,:,:5] #shape (32, 256, 5) \n",
    "\n",
    "    # print(f\"logits_top_k shape: {logits_top_k.shape}\")\n",
    "\n",
    "    # y = y_input.numpy() \n",
    "\n",
    "    # i = 0 \n",
    "    # num_correct = 0 \n",
    "    # num_total = 0 \n",
    "    # for indx in indices: \n",
    "    #     logits_top_k_preds = logits_top_k[i, indx, :] #shape (1, num_masks, 5)  \n",
    "    #     print(f\"logits_top_k_preds shape: {logits_top_k_preds.shape}\")\n",
    "    #     mask_answers = y[i, indx] #shape (1, num_masks)\n",
    "\n",
    "    #     print(f\"mask_answers shape: {mask_answers.shape}\")\n",
    "\n",
    "    #     for i in range(logits_top_k.shape[1]):\n",
    "    #         if mask_answers[i] in logits_top_k[0, i, :]:\n",
    "    #             num_correct += 1\n",
    "    #     num_total += logits_top_k.shape[1] \n",
    "    # return num_correct/num_total\n",
    "        \n",
    "    \n",
    "\n",
    "    # total = [0, 0] #(total correct, total guessed) \n",
    "    \n",
    "    # for i in range(batch): \n",
    "    #     indices = np.where(x_input[i] == 29999)\n",
    "\n",
    "    #     logits_argsort = np.argsort(logits[i], axis=-1)[::-1] \n",
    "    #     preds = logits_argsort[i,i,:5] #shape (32, 256, 5) \n",
    "\n",
    "    #     correct_words = y_input[i].numpy()[indices]\n",
    "\n",
    "    #     count = 0 \n",
    "    #     for i in range(min(len(predicted_words), len(correct_words))): \n",
    "    #         if correct_words[i] in preds:\n",
    "    #             total[i] += 1\n",
    "    #         total[i] += 1 \n",
    "    return total[0]/total[1]      \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e88d5229-b2d8-475d-a4ae-3fecae60734d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_input shape: (32, 256)\n",
      "logs shape: (26, 5)\n",
      "correct shape: (26,)\n",
      "[  895    48     3  1809   121  3672  1002  9443    15 11424 19187   136\n",
      "    50   365   784  8174   780     5   119     6   435    23  9617 16414\n",
      "    59    82]\n",
      "correct: write what and page does attached party habits with maniacal intrinsic such when start subject avoids elements of life to 3 are therein sharma she into\n",
      "preds: ['incident melodrama unconventional pertaining endear', 'abject kanes fortitude snake translating', 'alumni sexless goines outspoken commitment', 'slums dread alumni goines prof', 'pales chaplin populate furious underlining', 'elegant sentinel conroy sooooo furious', 'improvisational many detective furious tequila', 'rudy skipper begin trainer hoss', 'alumni garbo 69 performers slovenian', 'alumni 69 garbo rudy moronic', 'unconsciousness sondheims slave wisely virgil', 'enthusiastic enemys driveway cbc flirtatious', 'wisely virgil personifies experimented literal', 'wisely seminal keerthana robe soft', 'oven whimpering emperor ahole 79', 'underlining africa 79 wagners newscaster', 'gestures tortures battleship snail concepts', 'snail improvisational raunchy underlining 79', 'raunchy saved overplays denny madefortelevision', 'saved raunchy depended horseman frakes', 'tortures ratso kindhearted 9510 imprisons', 'rahul banners fahrenheit orton tortures', 'fahrenheit coat orton kindhearted dugan', 'outspoken orton coat coward phipps', 'kindhearted ratso udita spoiling hatches', 'flamingos emperor talos digest responding']\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(measure_acc(logits, x_input, y_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "471e53e9-b1c8-404f-a577-bfe47c8b2271",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = None \n",
    "y_input = None \n",
    "mask = None \n",
    "padding_mask = None\n",
    "for step, (x_input, y_input, mask, padding_mask) in enumerate(mlm_ds): \n",
    "    x_input = x_input \n",
    "    y_input = y_input \n",
    "    mask = mask \n",
    "    padding_mask = padding_mask \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "789835d8-55d9-474d-9459-6a530a42f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model((x_input, mask, padding_mask)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92044539-d926-48f0-be00-b3111e3af432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47f07e15-cb1d-49ab-9985-69e0d28aa7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.3624720e-05, 2.3650602e-05, 2.4203482e-05, ..., 4.5484216e-05,\n",
       "       4.5081844e-05, 4.4933997e-05], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.numpy()[0,0,logits_argsort[0,0,:-5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8948a2f-8475-4c88-8ff3-bc262eb9638a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 256, 30000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba59412b-4e53-4cec-a9ac-caebbb349558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12650,  4478, 17189, 29892, 13777])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_argsort[0][0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2220c8c5-031e-4da8-b579-0149b904c1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.3624720e-05, 2.3650602e-05, 2.4203482e-05, 2.4268829e-05,\n",
       "         2.4722051e-05],\n",
       "        [2.4384562e-05, 2.3588826e-05, 2.4317258e-05, 2.4596175e-05,\n",
       "         2.6424554e-05],\n",
       "        [2.5367803e-05, 2.4165518e-05, 2.4917123e-05, 2.5199330e-05,\n",
       "         2.8532308e-05],\n",
       "        ...,\n",
       "        [2.9357727e-05, 3.0069335e-05, 2.9820629e-05, 3.0462938e-05,\n",
       "         2.6266240e-05],\n",
       "        [2.9973031e-05, 3.0018720e-05, 3.0581850e-05, 2.9653955e-05,\n",
       "         2.6903224e-05],\n",
       "        [3.0156471e-05, 3.0119894e-05, 3.1214320e-05, 2.8417953e-05,\n",
       "         2.7636048e-05]],\n",
       "\n",
       "       [[2.3500072e-05, 2.3662180e-05, 2.4121982e-05, 2.4358731e-05,\n",
       "         2.4852736e-05],\n",
       "        [2.4267056e-05, 2.3901115e-05, 2.4372990e-05, 2.4697101e-05,\n",
       "         2.6273945e-05],\n",
       "        [2.5041390e-05, 2.4129708e-05, 2.4778832e-05, 2.4841740e-05,\n",
       "         2.8371784e-05],\n",
       "        ...,\n",
       "        [2.9363466e-05, 3.0075573e-05, 2.9824765e-05, 3.0461506e-05,\n",
       "         2.6261863e-05],\n",
       "        [2.9978637e-05, 3.0024787e-05, 3.0586783e-05, 2.9652525e-05,\n",
       "         2.6898755e-05],\n",
       "        [3.0164743e-05, 3.0127321e-05, 3.1220741e-05, 2.8417498e-05,\n",
       "         2.7633841e-05]],\n",
       "\n",
       "       [[2.3573008e-05, 2.3693823e-05, 2.3958872e-05, 2.4561699e-05,\n",
       "         2.4742367e-05],\n",
       "        [2.4346948e-05, 2.4169982e-05, 2.4304471e-05, 2.4408619e-05,\n",
       "         2.6061709e-05],\n",
       "        [2.5500565e-05, 2.4649245e-05, 2.4701905e-05, 2.5117504e-05,\n",
       "         2.8545313e-05],\n",
       "        ...,\n",
       "        [2.9405352e-05, 3.0016008e-05, 2.9926638e-05, 3.0559167e-05,\n",
       "         2.6394287e-05],\n",
       "        [2.9926066e-05, 2.9918881e-05, 3.0726460e-05, 2.9881021e-05,\n",
       "         2.7142527e-05],\n",
       "        [3.0082525e-05, 3.0056208e-05, 3.1110008e-05, 2.8518580e-05,\n",
       "         2.7925851e-05]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[2.3903511e-05, 2.3839624e-05, 2.4588231e-05, 2.4345050e-05,\n",
       "         2.4324894e-05],\n",
       "        [2.4668610e-05, 2.3891536e-05, 2.4723422e-05, 2.4473804e-05,\n",
       "         2.5767995e-05],\n",
       "        [2.5579906e-05, 2.4398651e-05, 2.5516098e-05, 2.5043419e-05,\n",
       "         2.7566533e-05],\n",
       "        ...,\n",
       "        [2.9343479e-05, 3.0073397e-05, 2.9809471e-05, 3.0459561e-05,\n",
       "         2.6262629e-05],\n",
       "        [2.9953731e-05, 3.0017054e-05, 3.0564795e-05, 2.9647948e-05,\n",
       "         2.6896972e-05],\n",
       "        [3.0137844e-05, 3.0114519e-05, 3.1201034e-05, 2.8413102e-05,\n",
       "         2.7623912e-05]],\n",
       "\n",
       "       [[2.3554610e-05, 2.3788560e-05, 2.4091069e-05, 2.4411827e-05,\n",
       "         2.4713676e-05],\n",
       "        [2.4354606e-05, 2.4143441e-05, 2.4255389e-05, 2.4472352e-05,\n",
       "         2.6206784e-05],\n",
       "        [2.5399117e-05, 2.4499726e-05, 2.4720179e-05, 2.4878769e-05,\n",
       "         2.8292046e-05],\n",
       "        ...,\n",
       "        [2.9457178e-05, 3.0054904e-05, 2.9986333e-05, 3.0603409e-05,\n",
       "         2.6484646e-05],\n",
       "        [2.9965891e-05, 2.9724433e-05, 3.0744231e-05, 2.9561323e-05,\n",
       "         2.7027028e-05],\n",
       "        [3.0070640e-05, 2.9962466e-05, 3.1295553e-05, 2.8645974e-05,\n",
       "         2.7859571e-05]],\n",
       "\n",
       "       [[2.3661325e-05, 2.3751150e-05, 2.4061152e-05, 2.4247658e-05,\n",
       "         2.4478433e-05],\n",
       "        [2.4427936e-05, 2.3936200e-05, 2.4501733e-05, 2.4483907e-05,\n",
       "         2.5967089e-05],\n",
       "        [2.5723302e-05, 2.4161598e-05, 2.5010573e-05, 2.4932147e-05,\n",
       "         2.8037404e-05],\n",
       "        ...,\n",
       "        [2.9351619e-05, 3.0073390e-05, 2.9815976e-05, 3.0462465e-05,\n",
       "         2.6264250e-05],\n",
       "        [2.9966217e-05, 3.0019884e-05, 3.0574232e-05, 2.9652789e-05,\n",
       "         2.6900681e-05],\n",
       "        [3.0150459e-05, 3.0120520e-05, 3.1210770e-05, 2.8416378e-05,\n",
       "         2.7631713e-05]]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_argsort = np.argsort(logits, axis=-1)[::-1] \n",
    "preds = logits_argsort[0,0,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f46f681-87dd-4d50-af23-3281d0543440",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([12650,  4478, 17189, 29892, 13777])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlogits_argsort\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/ops/array_ops.py:926\u001b[0m, in \u001b[0;36m_check_index\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m    921\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(idx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _SUPPORTED_SLICE_DTYPES \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    923\u001b[0m     idx\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(idx\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# TODO(slebedev): IndexError seems more appropriate here, but it\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# will break `_slice_helper` contract.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(_SLICE_TYPE_ERROR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(idx))\n",
      "\u001b[0;31mTypeError\u001b[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([12650,  4478, 17189, 29892, 13777])"
     ]
    }
   ],
   "source": [
    "print(logits[logits_argsort[0,0,:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70764092-7a06-4add-8245-ea5006678720",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = compile_model(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97da4cf3-6ae6-4a2b-beda-e719e5e74fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 3, 2, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = np.array([0, 1, 2, 3, 4 ,5 ]) \n",
    "np.argsort(logits)[::-1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2447eed5-d5c6-4368-9432-6dcfa0c9c278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m correct \u001b[38;5;241m=\u001b[39m [  \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m40\u001b[39m ,   \u001b[38;5;241m5\u001b[39m  , \u001b[38;5;241m65\u001b[39m ,  \u001b[38;5;241m24\u001b[39m, \u001b[38;5;241m1504\u001b[39m ,\u001b[38;5;241m1646\u001b[39m  , \u001b[38;5;241m59\u001b[39m ,\u001b[38;5;241m7182\u001b[39m ,  \u001b[38;5;241m41\u001b[39m , \u001b[38;5;241m123\u001b[39m,  \u001b[38;5;241m336\u001b[39m , \u001b[38;5;241m790\u001b[39m  ,\u001b[38;5;241m379\u001b[39m, \u001b[38;5;241m152\u001b[39m, \u001b[38;5;241m1543\u001b[39m , \u001b[38;5;241m145\u001b[39m ,  \u001b[38;5;241m89\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorrect\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dataset.py:95\u001b[0m, in \u001b[0;36mDataset.decode\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid2token)\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid2token\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m~/dataset.py:95\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid2token)\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid2token\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "correct = [  28, 40 ,   5  , 65 ,  24, 1504 ,1646  , 59 ,7182 ,  41 , 123,  336 , 790  ,379, 152, 1543 , 145 ,  89]\n",
    "dataset.decode(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97154e5-19b2-4aae-94ef-375078c71424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
