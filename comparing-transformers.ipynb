{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dfb7273-5525-4c47-b1f0-06dd43911a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import keras_nlp\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.layers import TextVectorization\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "from pprint import pprint\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "import re \n",
    "import sys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f60d8e-7060-4d0c-89a1-0aeaecfaccf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from '/home/jovyan/config.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import model \n",
    "import config\n",
    "import dataset\n",
    "from config import get_config, set_config_ratio\n",
    "from dataset import get_dataset_class\n",
    "from model import compile_model, get_optimizer\n",
    "importlib.reload(model)\n",
    "importlib.reload(dataset) \n",
    "importlib.reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a33ecd20-d0a8-4af7-b52a-6bae0b197482",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config() \n",
    "dataset = get_dataset_class(config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a5bcc86-8414-426a-bdc5-944caa048ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 19:04:42.188863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22400 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:89:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting generating masks...\n",
      "starting generating mask for 0/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 1000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 2000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 3000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 4000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 5000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 6000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 7000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 8000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 9000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 10000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 11000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 12000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 13000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 14000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 15000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 16000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 17000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 18000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 19000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 20000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 21000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 22000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 23000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 24000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 25000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 26000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 27000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 28000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 29000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 30000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 31000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 32000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 33000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 34000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 35000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 36000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 37000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 38000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 39000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 40000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 41000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 42000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 43000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 44000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 45000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 46000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 47000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 48000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "starting generating mask for 49000/50000 sentence...\n",
      "finished generating mask for 1 sentence\n",
      "exited loop\n",
      "converted mask to numpy array\n",
      "finished generating mask\n",
      "started forming dataset\n",
      "finished forming dataset\n"
     ]
    }
   ],
   "source": [
    "mlm_ds = dataset.generate_dataset().shuffle(1000).batch(config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36feb445-c716-4d1d-b253-7423fc4fa603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLanguageModel(keras.Model):\n",
    "    def train_step(self, inputs):\n",
    "        if len(inputs) == 3:\n",
    "            features, labels, sample_weight = inputs\n",
    "        else:\n",
    "            features, labels = inputs\n",
    "            sample_weight = None\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(features, training=True)\n",
    "            loss = loss_fn(labels, predictions, sample_weight=sample_weight)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Compute our own metrics\n",
    "        loss_tracker.update_state(loss, sample_weight=sample_weight)\n",
    "\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We list our `Metric` objects here so that `reset_states()` can be\n",
    "        # called automatically at the start of each epoch\n",
    "        # or at the start of `evaluate()`.\n",
    "        # If you don't implement this property, you have to call\n",
    "        # `reset_states()` yourself at the time of your choosing.\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07fab6e4-5edb-4684-80ef-231d9c5b7437",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = keras.models.load_model('saved_models/model_ratio_0.0', compile=False)\n",
    "optim = get_optimizer()\n",
    "my_model.compile(optimizer=optim, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93df6f51-e6b5-4ed7-9853-f5ccdf808026",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = keras.models.load_model(\n",
    "    \"bert_mlm_imdb.keras\", custom_objects={\"MaskedLanguageModel\": MaskedLanguageModel}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a69a588-9ade-4f2c-9fcd-c50d9b6f9e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_loss_fn = keras.losses.SparseCategoricalCrossentropy(reduction=\"none\")\n",
    "b_loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "m_loss_fn = keras.losses.SparseCategoricalCrossentropy(reduction=\"none\")\n",
    "m_loss_tracker = keras.metrics.Mean(name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6af11c54-9e4f-4f1e-843f-477801a2bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = next(iter(mlm_ds.take(1)))\n",
    "x, y, mask, padding_mask, sample_weights = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7427616-7899-4122-bddf-e2b71a96dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_out = baseline_model(x) \n",
    "my_out, attention = my_model((x, mask, padding_mask)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "516952ee-a4ba-4702-8f4c-98f1a931eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_bout = base_out.numpy() \n",
    "real_mout = my_out.numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97c4b32b-b393-4cac-9b09-a6ed93ee19b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_preds = np.argmax(real_bout[0], axis=-1)\n",
    "m_preds = np.argmax(my_out[0], axis=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26b91013-50c1-47f4-a6c1-ff23f16b77b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_loss = b_loss_fn(y, base_out, sample_weight=sample_weights)\n",
    "m_loss = m_loss_fn(y, my_out, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d895b586-f3fc-49ed-a128-c5b4d0100368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b loss: [[0.         0.         0.         ... 2.9859133  0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.08079843 0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "m loss: [[0.        0.        0.        ... 3.2821004 0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.4281662 0.        0.        ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"b loss: {b_loss}\") \n",
    "print(f\"m loss: {m_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccca33df-1700-40d5-ade6-c2f2f1af02c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline loss: 6.950923442840576\n",
      "my model loss: 6.768109321594238\n"
     ]
    }
   ],
   "source": [
    "b_loss_tracker.update_state(b_loss, sample_weight=sample_weights)\n",
    "m_loss_tracker.update_state(m_loss, sample_weight=sample_weights) \n",
    "print(f\"baseline loss: {b_loss_tracker.result()}\")\n",
    "print(f\"my model loss: {m_loss_tracker.result()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ec4ba2d-81a6-42bd-b341-e9b88bbdb68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 7.006988048553467\n"
     ]
    }
   ],
   "source": [
    "loss_tracker.update_state(m_loss, sample_weight=sample_weights)\n",
    "print(f\"loss: {loss_tracker.result()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8965d9-20f9-4228-b983-7da27fedf1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
